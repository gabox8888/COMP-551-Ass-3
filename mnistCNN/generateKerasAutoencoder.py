from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D
from keras.models import Model
from keras.models import load_model
from sklearn.neighbors import KNeighborsClassifier
import numpy as np, os, sys
from keras.preprocessing.image import ImageDataGenerator
import warnings


### Based on: https://blog.keras.io/building-autoencoders-in-keras.html ###

# This is the size of our encoded representations
# Input placeholder
input_img = Input(shape=(28,28,1))

x = Convolution2D(16, 3, 3, activation='relu', border_mode='same', input_shape=(28, 28, 1))(input_img)
x = MaxPooling2D((2, 2), border_mode='same')(x)
x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)
x = MaxPooling2D((2, 2), border_mode='same')(x)
x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)
encoded = MaxPooling2D((2, 2), border_mode='same')(x)

x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(encoded)
x = UpSampling2D((2, 2))(x)
x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)
x = UpSampling2D((2, 2))(x)
x = Convolution2D(16, 3, 3, activation='relu')(x)
x = UpSampling2D((2, 2))(x)
decoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
# this model maps an input to its encoded representation
encoder = Model(input=input_img, output=encoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
# Dataset
from keras.datasets import mnist
(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) #np.prod(x_train.shape[1:])))
x_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) #np.prod(x_test.shape[1:])))
print x_train.shape
print x_test.shape	

# Generate noisy versions
noise_factor  = 0.2
x_train_noisy = x_train + np.random.choice( [0, 0.95], size=x_train.shape, p=[0.9, 0.1] )  
#np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) 
x_test_noisy  = x_test + np.random.choice( [0, 0.95], size=x_test.shape, p=[0.9, 0.1] ) 
#np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) 
x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy  = np.clip(x_test_noisy, 0., 1.)

# This will do preprocessing and realtime data augmentation
datagen = ImageDataGenerator(
	featurewise_center=False,  # set input mean to 0 over the dataset
	samplewise_center=False,  # set each sample mean to 0
	featurewise_std_normalization=False,  # divide inputs by std of the dataset
	samplewise_std_normalization=False,  # divide each input by its std
	zca_whitening=False,  # apply ZCA whitening
	rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
	width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
	height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
	horizontal_flip=False,  # randomly flip images
	vertical_flip=False)  # randomly flip images

# Parameters
nb_epoch = 40
batch_size = 128
spe = x_train.shape[0] * 2

# Compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
datagen.fit(x_train)

# fit the model on the batches generated by datagen.flow()
autoencoder.fit_generator(
		datagen.flow( x_train_noisy, 
			      x_train,
			      batch_size=batch_size),
		samples_per_epoch=spe,
		nb_epoch=nb_epoch,
		verbose=1,
		validation_data=(x_test_noisy, x_test))

# Save encoder
print("Saving model")
autoencoder.save('mnist_autoencoder_wshifting.h5')
# encode and decode some digits
# note that we take them from the *test* set
encoded_imgs = encoder.predict(x_test)
print(encoded_imgs)




